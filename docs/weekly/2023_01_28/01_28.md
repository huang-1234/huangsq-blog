# 0128 




## 为什么要用 pnpm 而不是 yarn/npm

### 对依赖包安装的底层实现不同
​		yarn 和 pnpm 都有 workspace 的功能，然而两者对依赖包安装的底层实现是千差万别的，yarn 的策略是和 npm 类似的，会将公共依赖提升到顶层的 node_modules 目录中，这样按照 node 的模块解析策略略，如果某个依赖在自己的 node_modules 中无法找到，则会逐级向上找，由于 yarn 将公共模块提升了，因此可以在顶层的 node_modules 中找到这个依赖。
​		这个策略初看好像没什么大问题，但是仔细一想还是有点问题的，现在我们考虑这样一个场景：

- B 依赖了 A，并将 A 写进了 B 的 package.json 的 dependencies 中
- C 依赖了 A，并将 A 写进了 C 的 package.json 的 dependencies 中
- D 依赖了 A，但没有将将 A 写进 D 的 package.json 的 dependencies 中

​		根据 yarn 的提升策略，A 会被提升到顶层的 node_modules 中，这时候在本地开发的时候，你基本没可能发现 D 的 package.json 的 dependencies 中少了 A，因为在 D 中依赖 A 的时候，模块解析在自己的 node_modules 中找不到 A 的时候，会逐级向上找，找到了顶层 node_modules，开发时你不会发现依赖缺失的问题。可一旦 D 发布之后，用户安装到本地之后，执行 D 的代码的时候，就会出现依赖 A 找不到的问题，这种问题如果使用 yarn 的话只有发布之后才能发现。

​		而 pnpm 采用的策略和 yarn 完全不一样，pnpm 会保证每个包的第一级 node_modules 中有且只有这个包的 dependencies 和 devDependencies 中所声明的依赖，不会将公共依赖提升，且 pnpm 会保证每个包下的 node_modules 的目录拓扑结构和 package.json 的完全一致，这可以解决 yarn 提升之后导致的依赖缺失但无法在开发阶段发现的问题。
​		pnpm 的 --global-style 可以禁止模块提升行为，但是使用 --global-style 会导致大量的模块重复安装，速度变慢且占用体积变大，而且可能会导致一些问题，比如有副作用的包多次引入会报错（比如 babel-polyfill），同一个模块的内部变量在两个不同目录下导致无法共享（比如 React 有一些内部变量，但是使用 --global-style 的时候，在两个不同包引入的 React 不是同一个模块实例，因此无法共享内部变量）等等。
​		pnpm 采用了统一的模块存储和硬链接的方法在避免模块提升导致拓扑结构变化的同时保证了不会让同一个版本的包重复安装多次，有关 pnpm 的 node_modules 结构详情可以查看官方的解释文档：https://pnpm.js.org/blog/2020/05/27/flat-node-modules-is-not-the-only-way。

### 可能遇到的问题：
1. pnpm 版本在 package.json 中有要求，文档中的 pnpm 安装语句建议指定版本
2. 执行 npm link 时，提示 `verbose stack Error: Unsupported URL Type "workspace:": workspace:^1.0.3`，经查需要升级 npm 到最新（v7）
3. 继续执行 `eden -v`，执行的文件是 `bin/cli.js` 而不是 `bin/cli-dev.js`，发现是 link 后没有更新 `/usr/local/bin/eden`，即该命令仍然指向 `bin/cli.js`，可能和我安装 node 的方式有关，我是官网下载安装包安装的，此处先删除原先安装的 eden，重新 npm link 即可


## npm依赖版本锁定
- npm包管理原理

​		在思考解决方案前，首先了解下npm包管理及依赖版本管理的原理。这些都是通过package.json文件实现的。
​		当你使用npm安装一个包(并保存它)或者更新一个包的时候，package.json里就自动添加了一条信息，包括包名和其版本。npm默认安装最新版本，然后在其版本号之前添加一个^符号。比如^1.2.12，它表明最低应使用1.2.12版本。并且在这之上，拥有相同大版本号的任何版本都是OK的。毕竟小版本和bugfix版本不会对使用造成任何影响，所以用任何相同大版本的更高级版本都很安全。

符号^：表示主版本固定的情况下，可更新最新版。例如：vuex: "^3.1.3"，3.1.3及其以上的3.x.x都是满足的。

符号~：表示次版本固定的情况下，可更新最新版。如：vuex: "~3.1.3"，3.1.3及其以上的3.1.x都是满足的。

无符号：无符号表示固定版本号，例如：vuex: "3.1.3"，此时一定是安装3.1.3版本。

举例：
"^1.2.3": 大于等于 1.2.3 且小于 2.0.0版本
"^0.3.4": 大于等于 0.3.4 且小于 0.4.0版本
"^0.0.6": 大于等于 0.0.6 且小于 0.0.7版本

- 版本依赖为什么需要锁定

​		没有版本锁定的情况下，在执行每次npm i的时候，对应的版本前都有个 ^ 符号。也就是未固定版本的依赖如果有了次版本更新或者修订版本更新，会自动安装对应的最新版。
在这种情况下，你再次install时安装的包的版本可能与前次不一样，具体的，你可以到package-lock.json中查看实际的包版本。
例如：A新建了一个项目，生成了上面这份package.json文件，但A安装依赖的时间比较早，此时packageA的最新版本是2.1.0，该版本与代码兼容，没有出现bug。后来B克隆了A的项目，在安装依赖时packageA的最新版本是2.2.0，那么根据语义npm会去安装2.2.0的版本，但2.2.0版本的API可能发生了改动，导致代码出现bug。

​		这就是package.json会带来的问题，同一份package.json在不同的时间和环境下安装会产生不同的结果。

​		理论上这个问题是不应该出现的，因为npm作为开源世界的一部分，也遵循一个发布原则：相同大版本号下的新版本应该兼容旧版本。即2.1.0升级到2.2.0时API不应该发生变化。但很多开源库的开发者并没有严格遵守这个发布原则，导致了上面的这个问题。

​		为了在不同的环境下生成相同的node_modules，引入版本依赖锁定就尤为必要了。

npm5.0之前可以通过npmshrinkwrap实现。通过运行 npm shrinkwrap，会在当前目录下生成一个 npm-shrinkwrap.json文件，里面包含了通过当前 node_modules 计算出的模块的依赖树及版本。只要目录下有 npm-shrinkwrap.json ，则运行 npm install 的时候会优先使用 npm-shrinkwrap.json 进行安装，没有则使用 package.json 进行安装。

​		在npm5.0之后,npm自带了package-lock.json文件，通过npm安装依赖，每当node_modules目录或者package.json发生变化时就会生成或者更新这个文件。不同版本有有些不同：

​		npm 5.0.x版本：不管package.json中依赖是否有更新，npm i都会根据package-lock.json下载。针对这种安装策略，有人提出了这个issue - #16866 ，然后就演变成了5.1.0版本后的规则。
5.1.0版本后：当package.json中的依赖项有新版本时，npm install会无视package-lock.json去下载新版本的依赖项并且更新package-lock.json。针对这种安装策略，又有人提出了一个issue - #17979，参考 npm 贡献者 iarna 的评论，得出5.4.2版本后的规则。
5.4.2版本后：
​		如果只有一个package.json文件，运行npm i会根据它生成一个package-lock.json文件，这个文件相当于本次install的一个快照，它不仅记录了package.json指明的直接依赖的版本，也记录了间接依赖的版本。
如果package.json的semver-range version和package-lock.json中版本兼容(package-lock.json版本在package.json指定的版本范围内)，即使此时package.json中有新的版本，执行npm i也还是会根据package-lock.json下载 - 实践场景1。
如果手动修改了package.json的version ranges，且和package-lock.json中版本不兼容，那么执行npm i时package-lock.json将会更新到兼容package.json的版本 - 实践场景2。

​		如果需要更新依赖依赖包版本，需要手动修改package.json中对应的版本或者指定依赖的版本号安装：npm i xxx@x.x.x。

- 更换/管理npm源

​		首先要说的是，很多同学可能习惯使用cnpm，因为安装速度确实比npm快不少，但在版本依赖锁定方案中，最基础的一条就是：不要使用cnpm，因为cnpm，是不支持依赖版本锁定的。也即是说，无论你的项目中有package-lock.json、npm-shrinkwrap.json还是yarn-lock.json文件，执行cnpm i安装依赖的时候他们都只是摆设，都只会根据package.json文件进行安装。所以通过cnpm安装依赖是不能避免上面问题的。而且有很多网友反馈cnpm会有依赖包丢失的问题。

​		但是使用npm避不开的一个问题就是安装速度，实在太慢了。这里我们可以通过手动更换npm源和nrm的方式实现使用npm命令的同时，依然享受cnpm的安装速度。

- 手动更换npm源

设置npm源： npm config set registry [url]

查看确认: npm config get registry

使用nrm
安装nrm

npm i nrm -g
查看可选的源

nrm ls


其中，带*的是当前使用的源，上面的输出表明当前源是官方源。
切换到某个源:nrm use xx
例如切换到淘宝源：nrm use taobao

增加源（添加企业内部的私有源或者其他源）：nrm add [registryName] [url]

删除源：nrm del `<registryName>`

测试某个源的相应时间：nrm test taobao

依赖版本锁定方案
大概有这么几条方案：

package.json中固定版本
npm+package-lock.json
npm+npm-shrinkwrap.json
yarn+yarn-lock.json
package.json中固定版本
		最直接的，可以在package.json中写入固定版本号，也就是去掉版本号前面的~或者^，或者安装的时候加上--save-exact参数。但这样只能锁定最外一层的依赖，也就是这个依赖本身的其他依赖版本是不受控制的。所以不太推荐。

npm+package-lock.json
		第一次npm i的时候会根据当前node_modules目录生成一个固定版本号的package-lock.json文件，后面如果安装新增的依赖，会自动更新这个文件。但如果需要更新当前某个依赖的版本号并锁定到package-lock.josn中，需要手动修改package.json中对应的版本或者指定依赖的版本号安装：npm i xxx@x.x.x。

npm+npm-shrinkwrap.json
		这种方式锁定版本，每次依赖有新增或者版本更新之后，要手动智行npm shrinkwrap来生成或者更新版本锁定文件。

yarn+yarn-lock.json
yarn-lock.json与package-lock.josn原理类似，习惯用yarn命令的可以采取这种方式。

注：
		如果项目中同时存在package-lock.json和npm-shrinkwrap.json,npm5 只会更新它，而不会生成 package-lock.json。
yarn 的锁定版本文件叫 yarn.lock，目前发布平台是支持的，不过最好保证项目中只有一个版本锁定文件，package-lock.json、npm-shrinkwrap.json 或者 yarn.lock 二选一，防止出现安装结果和预想不一致的情况。
npm和cnpm的区别
cnpm i不受package-lock.json影响，只会根据package.json进行下载。
cnpm i xxx@xxx不会更新到package-lock.json中去。
npm i xxx@xxx会跟新到package-lock.json中去



## 硬链接(hard link)和符号连接(symbolic link)的区别

​		硬链接(hard link)和符号连接(symbolic link)的区别：

​		通俗一点理解，可以把硬链接当成源文件的副本，他和源文件一样的大小但是事实上却不占任何空间。
符号链接可以理解为类似windows一样的快捷方式。

#### 一、链接文件
链接文件有两种方式，符号链接和硬链接。

1、符号链接文件
符号链接，这个文件包含了另一个文件的路径名。可以是任意文件或目录，也可以链接不同文件系统的文件。甚至可以链接不存在的文件，这就产生一般称为“断裂”的问题（现象），还可以不断的循环链接自己。
用ln -s 命令可以生成一个符号链接，如下所示：
#ln -s source_file  softlink_file
在对符号链接进行读写操作的时候，系统会自动把该操作转换为对源文件的操作。但是删除链接文件时，系统仅仅删除符号链接文件，而不删除源文件本身。

2、硬链接文件
硬链接的命令是：
#ln existfile  newfile
硬链接文件有两个限制
1）、不允许给目录创建硬链接
2）、只允许在同一文件系统中的文件之间才能创建链接

对于硬练级文件进行读写和删除操作的时候，结果和符号链接相同。但是如果我们删除硬链接文件的源文件，硬链接文件仍存在，而且保留了原有的内容。

#### 二、两者之间的区别
​		硬链接是通过索引节点(inode index)来进行链接的。在linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给他分配一个编号，称为索引节点号（inode index）。

在linux中，多个文件名指向同一索引点是存在的。一般这种链接是硬链接。硬链接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬链接到重要文件，起到防止“误删”的功能。
因为对应目录的索引节点有一个以上的链接，只删除一个链接并不影响索引节点本身和其他的链接，只有当最后一个链接被删除后，文件的数据块及目录的链接才会被释放。也就是说，至此文件才被真正删除。

符号链接文件有点类似于windows的快捷方式。他实际上是特殊文件的一种。在符号链接中，文件实际上是一个文本文件，他包含了另一个文件的位置信息。

#### 三、体会
​		符号链接（symbolic link）在建立的时候建立了一个新的inode，并记录了指向源文件inode的路径。所以symbolic的inode number跟原始档案的inode number是不一样的。这也是为什么symbolic link能够跨越不同文件系统的原因。
符号链接建立了新的inode number，所以它是一个真实的文件并占有一定的磁盘空间。另外对symbolic link的操作除了删除都会直接对源文件进行操作。
​		硬链接（hard link）并没有新建立inode，而是新建了一个内容以及inode number、hard link文件名和其他相关资讯的一个directory entry，所以hard link的inode number跟源文件的
inode number是一样的。因为一个文件系统有着相同的inode number，所以hard link是不可以跨文件系统创建的。也可以将hard link理解为不是一个文件，把它看成是同一个inode的别名，
建立hard link后他和源文件互为别名，删除其中任何一个，inode都不会释放。只有指向同一inode的文件名都删除后，inode才释放。hard link实际上是不占空间的。



## 从pnpm了解软硬链接的应用

​		从2017年pnpm的诞生，到现在各公司都在去npm、yarn化，pnpm正在陆续接管各大前端项目的依赖包安装。原因在于她使用软链接和硬链接的方式不仅提高了安装速度还节约了磁盘空间，同时避免了依赖分身和幽灵依赖等问题。

这篇文章先对比一下npm、yarn、pnpm的区别，再了解一下硬链接和软链接的应用。开始吧。

### npm

老牌包管理工具npm的成功主要原因是Node的横行，引入了package.json文件，将所有的依赖都添加到了package.json中，比如运行 npm install --save lodash，以下几行将会添加到package.json中。

```json
  "dependencies": {
    "lodash": "^4.17.21"
  }
```

​		lodash版本前的^符号意思是安装主版本等于4的任意一个版本即可。所以两个人不同时间的安装是会出现不同版本的情况的。虽然说小版本升级一般会兼容上一个版本，但是升级翻车的事情也是屡见不鲜的。要想版本完全一致，lock版本或使用docker。说回来，npm的包大多都是依赖于其他npm包的，这会导致嵌套依赖关系并增加无法匹配想要版本的几率。

​		虽然说我们可以锁住安装包的版本，但是包的依赖取决于其本身的package.json的写法。我们也无法控制。为了解决这个问题，npm提供了shrinkwrap命令，此命令会生成一个npm-shrinkwrap.json的文件，用来记录所有包及其依赖包的确切版本。 这个命令很好用，但是知名度好像不高。问过身边好几个同事，都不清楚这个命令。如此好用的命令也是只能保证我们在版本问题上不出问题。对于包内容的变更还是不会检测的。

​		现在npm的版本早就解决了npm2上嵌套依赖树的问题。因为这个结构在一些场景下会变得很长，这对于Unix操作系统来说是个问题。因为很多程序是无法处理超过260个字符的文件路径的。

### yarn

2016年yarn的出现主要解决了npm的两个主要问题，

1. 语义控制导致npm安装不确定的问题。
2. npm安装包依赖嵌套的的问题（虽然npm3及时的解决了这个问题）。

​		上面说npm可以通过`shrinkwrap` 命令来生成npm-shrinkwrap.json的文件来控制安装包及其依赖包的版本问题。而yarn是可以直接生成yarn.lock文件的，**默认生成的**。 高手过招，胜负往往就在半招之间。人的惰性让默认选项更胜一筹。yarn 不仅可以控制安装包版本，还可以对安装包内容进行校验。

```yaml
lodash@^4.17.21:
  version "4.17.21"
  resolved "https://registry.npmmirror.com/lodash/-/lodash-4.17.21.tgz#679591c564c3bffaae8454cf0b3df370c3d6911c"
  integrity sha512-v2kDEe57lecTulaDIuNTPy3Ry4gLGJ6Z1O3vE1krgXZNrsQ+LFTGHVxVjcXPs17LhbZVGedAJv8XZ1tvj5FvSg==
```

​		intergrity 是对resolved 下载下来的文件进行完整性校验，如果出现了diff，就说明下载链接对应的文件被修改过。安装的时候就会给出提示，安全性进一步增强了。

另外在速度上面，yarn的并行下载也会让其下载速度快很多。

### pnpm

而pnpm算是站在了巨人的肩膀上，当然这个巨人不是npm和yarn，而是软链接和硬链接。

pnpm相比于前辈们最大的不同就是快和空间管理。

在快方面，官方的图有些量化的依据。

<img src="https://img.manster.me/2022/06/docker/Snipaste_2022-09-04_20-10-17.png" alt="img" style="zoom:50%;" />

pnpm能有这么快的安装速度得益于她的包管理机制，速度上能快2~3呗。稍微大一点的项目，在部署环节install的时候能减少不少时间。

### 非扁平的结构

yarn和npm安装依赖包，会在node_modules下都平铺出来。比如你install一个包 express，但是你的node_modules下会有很多包。

<img src="https://img.manster.me/2022/06/docker/Snipaste_2022-09-04_20-24-08.png?" alt="img" style="zoom:50%;" />

这个时候会有一些问题

- 幽灵依赖

  从目前的包引用方式来说，inport的时候我们会从node_modules的文件夹中寻找，按照上面的图中所示，如果我们在package.json中没有accepts，其实我们也是可以引用到的，因为她确实存在，这时候我们访问的就是未申明npm包，如果某一天express不再依赖accepts，这个时候项目就会有依赖缺失的问题。 我们把这种主包依赖的子包，未被申明而在项目中使用，我们称之为 幽灵依赖。

- 包版本的不确定性

  这个很好理解，如果A、B两个主包都依赖accepts包，但是A依赖accepts@1.0，B依赖accepts@2.0 ，那node_modules下的扁平结构是展示1.0 还是 2.0 呢？目前的方式是谁后安装的谁就显示。 这种不确定性在开发中引起的问题也不在少数 「别人用这个包可以解决这个问题，但是我安装这个包就不能解决」，往往就是这个原因导致的。

- 依赖重复安装

  这个也很好理解，AB都依赖accepts，依赖不同的版本，无论node_modules的顶层提升了哪个版本，这个包都是会被安装两次的。

另外，我们都会发现一个问题。比如我们一般都会将公司的项目clone到一个以公司命名的文件夹中，随着项目的增多，和开发的增加。你会发现这个文件夹变的巨大无比，其中我们的业务代码只占其中30%左右，剩余的都是node_modules中的依赖包。而这其中的依赖包，有很大比例都是一样的。这也会疯狂的占据我们的磁盘空间。

​		pnpm的包管理方式是通过**建立链接的方式**来完成快速安装和防止重复安装（以减少磁盘空间）的问题。

​		其实说到安装也不是说非要从哪里下载下来，只要有个产物可以供我消费，无论我是安装下来还是可以从网上直接用（cdn）或者源文件在其他地方我link一下，都可以，达到供我消费的目的就可以。

​		说真的，在业务开发当中，我们主要关心的是业务代码，而安装的依赖，一般我们都不怎么刻意关心。话说回来，我们可以先看一下pnpm的产物。

![img](https://img.manster.me/2022/06/docker/Snipaste_2022-09-04_21-39-12.png)

我们可以看到node_modules下面很干净，只有express和.pnpm文件夹，相比于npm和yarn的产物，清爽了不少。

我们看一下pnpm官方对这一现象的图示说明

<img src="https://img.manster.me/2022/06/docker/node-modules-structure-8ab301ddaed3b7530858b233f5b3be57.jpeg" alt="img" style="zoom:50%;" />

​		顶级外层来看，格式很清晰，.pnpm中也是嵌套的。这是因为pnpm的node_modules布局使用的是符号链接来创建依赖关系的嵌套结构。pnpm内部的每个包中的每个文件都是只用硬链接指向了.pnpm store 中的文件。

​		这样的好处就是会让我们的node_modules很清晰，内部的包可以和package.json中的依赖对应起来，一目了然，我们安装什么里面就有什么。

​		这样幽灵依赖的问题就解决了，包版本不确定性的问题也就解决了。毕竟顶层就只有我们手动安装的包，其他依赖包都收在.pnpm中。这样无论是哪个版本都会平铺在这里供你消费。 这个平铺的方式就是通过链接的形式进行引用。好，我们知道了pnpm是通过hard link（硬链接）的方式来提升能力。那我们要聊一下她的使用和应用了

### hard link

> 来自维基百科的解释：**硬链接（英语：hard link）**是计算机文件系统中的多个文件平等地共享同一个文件存储单元（如MFT条目、inode）。硬链接必须在同一个文件系统中；一般用户权限下的硬链接只能用于文件，不能用于目录，因为其父目录就有歧义了。删除一个文件名字后，还可以用其它名字继续访问该文件。硬链接只能用于同一个文件系统（对于NTFS是限制于同一个分区）。不能用于不存在的文件。

​		要想进一步了解硬链接我们需要从inode说起，大概的我们用大白话讲一下。

​		一个文件存储在硬盘上，硬盘最小的存储单位叫做扇区（0.5kb），系统读取的时候会一次性读8个扇区，我们称之为块。我们还需要找个地方用来存储这个文件的基本信息，这个东西我们就叫做inode。举个例子，我会把收纳的东西放到一个小盒子里，然后我会将8个小盒子放到抽屉里。我找东西的时候是会拉开抽屉同时看到8个小盒子的。这样我找起来也会快一点。但是更前提是我得先找到抽屉的把手，然后拉开抽屉。 这样盒子对应的是扇区，抽屉对应着块，抽屉的把手对应着inode。

inode的基本信息有很多，包括

- 文件的字节数
- 文件拥有者的User ID
- 文件的Group ID
- 文件的读、写、执行权限
- 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。
- 链接数，即有多少文件名指向这个inode
- 文件数据block的位置

使用 stat xxx.txt 命令 可以查看inode信息。

​		每个inode都有一个号码，这个在操作系统中是独一无二的。操作系统就是用过这个号码找到文件的。所以说，**我们表面上是打开一个文件，实际上是系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据**。

使用ls -i命令，可以看到文件名对应的inode号码: ls -i xxx.txt

​		同样的命令可以作用于文件夹，因为在Unix/Linux系统中，文件夹（目录）也是一种文件。一般情况下，文件名和inode号码是"一一对应"关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为"硬链接"（hard link）。

使用 ln 命令可以创建硬链接：

```
ln 源文件 目标文件
```

硬链接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬链接到重要文件，起到防止“误删”的功能。

举个例子：

我们创建一个文件 a.txt，touch a.txt，然后 vi a.txt，我们输入点字符，this is a。这个时候我们执行 ln a.txt b.txt。这个时候再执行 ls。我们会发现。

```
(base) ➜ ls
a.txt b.txt
```

​		有两个文件。然后我们 vi b.txt ，发现了一行 this is a。说明现在 a就是b，b就是a。然后我们 rm a.txt，这个时候发现就剩下 b.txt。 但是我们打开 b.txt ， 还是可以看到this is a。

​		所以说硬链接是可以防止误删的。一点毛病没有。这个时候有人就会问了，那我怎么才能都删了呢？好问题，自古评论区人才济济，这个就交给大家讨论了。

具体还有哪些应用呢？

### 文件分类

​		比如我有一个文件夹，存储了10 个G的照片。这些照片中的人物、拍照地点、拍照时间都是不一样的。现在，我既想根据照片中的人物进行分类，也想根据拍照地点进行分类，还想根据拍照时间进行分类，那该怎么办?因为一张照片可能同时属于多个不同的分类，难道每个分类中都复制一张照片?这样也太浪费硬盘空间了!

**解决方案是**：

​		所有的照片仍旧放在一个总的文件夹中，然后创建不同的分类文件夹，在每个分类文件夹中，创建硬链接到目标照片文件。这样的话，不仅对照片进行了分类，而且一点都不占用硬盘空间。

### 文件多人共享

<img src="https://s4.51cto.com/oss/202106/18/ec2a31d64709e4939902481c64c56455.png" alt="img" style="zoom:50%;" />

​		当很多人同时对同一个文件进行维护的时候，如果大家都直接操作这个文件，万一不小心把文件删除了，大家就都玩完了!此时，可以在每个人自己的私人目录中，创建一个硬链接。每次只需要对这个硬链接文件进行操作，所有的改动会自动同步到目标文件中。由于每个人都是操作硬链接文件，即使不小心删除了，也不会导致文件的丢失。因为删除硬链接文件，仅仅是把该文件的 inode 节点中的 links 值减 1 而已，只要不为 0，就不会真正的删除文件。

### 文件备份

​		一些小伙伴有定期备份文件、清理文件的好习惯。在备份的时候，如果是实实在在的拷贝一份，那真的是太浪费磁盘空间，特别是对于我这种只有 256G 硬盘空间的笔记本。此时，就可以利用硬链接功能，既实现文件备份的目的，又节省了大量的硬盘空间，一举两得!很多备份工具利用的就是硬链接的功能，包括 git 工具，当克隆本地的一个仓库时，执行 clone 指令：

```
git clone --reference <repository> 
```

​		git 并不会把仓库中的所有文件拷贝到本地，而仅仅是创建文件的硬链接，几乎是零拷贝!

### symbolic link

​		除了硬链接以外，还有一种特殊情况。符号链接也成为软链接。文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的"软链接"（soft link）或者"符号链接（symbolic link）。

​		这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错："No such file or directory"。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode"链接数"不会因此发生变化。

ln -s命令可以创建软链接。

> ln -s 源文件 目标文件

### 灵活切换不同版本的目标程序

​		在开发的过程中，对于同一个工具软件，可能要安装多个不同的版本，例如：Python2 和 Python3， JDK8 和 JDK9 等等。此时就可以通过软链接来指定当前使用哪个版本。例如在我的电脑中：

```
$ ll -l /usr/bin/python* 
lrwxrwxrwx 1 root root       9 12月 31 08:19 /usr/bin/python -> python2.7* 
lrwxrwxrwx 1 root root       9 12月 31 08:19 /usr/bin/python2 -> python2.7* 
-rwxr-xr-x 1 root root 3492624 3月   2 04:47 /usr/bin/python2.7* 
lrwxrwxrwx 1 root root       9 12月 31 08:19 /usr/bin/python3 -> python3.5* 
-rwxr-xr-x 2 root root 4456208 1月  27 02:48 /usr/bin/python3.5* 
```

​		当在终端窗口中输入：python 时，启动的是 python2.7 版本。如果有一天我需要使用 python3.5 版本，只需要把软链接 python 指向 python3.5 即可。

### 快捷方式

利用软链接的快捷方式功能就比较好理解了，想一想：我们为什么在 Windows 的桌面上创建很多软件的快捷方式啊？在 Linux 中同样如此!

​		比如：最近一段时间的工作，每次都要打开一个路径很深的文件。如果在资源管理器中，一层一层的点击鼠标，是不是比较浪费时间。此时，就可以在桌面上创建一个软链接，每次直接双击就打开所链接的目标文件了。

### 总结

​		pnpm后来者居上，让我们有了解决npm包的新方式。使用pnpm的同时我们更应该了解一下背后基础技术的原理和方式。有可以会打开新的视野思路。就好比张无忌练乾坤大挪移那么快那么强，离不开九阳真经的背后加持。那我们如果掌握了九阳真经那我们就不止于乾坤大挪移了，太极拳剑、圣火令武功等也是可以搞搞的。
